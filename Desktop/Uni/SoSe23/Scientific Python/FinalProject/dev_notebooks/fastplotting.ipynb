{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from db_connector import DB_Connector\n",
    "from plotter import DataFramePlotter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_html_from_url(url):\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "    # Send HTTP request to site and save the response from server in a response object called r\n",
    "    r = requests.get(url, headers=headers)\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Extract the desired info (the offers in this case)\n",
    "    # The selector depends on the structure of the webpage, inspect the webpage to find the right selector\n",
    "    offers = soup.select('div.offer')\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 429:  # HTTP 429 means Too Many Requests / 500 server error\n",
    "            print(\"Hit rate limit, sleeping for a bit...\")\n",
    "            time.sleep(5)  # Wait for 10 seconds before trying again\n",
    "            continue\n",
    "\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(\"Encountered Server Error, sleeping for a bit longer...\")\n",
    "            time.sleep(240)  # Wait for 10 seconds before trying again\n",
    "            continue\n",
    "\n",
    "        # If the response was not a 429, break the loop\n",
    "        break\n",
    "\n",
    "    # You might also want to check here if the response was a 200 OK\n",
    "    # If not, you could raise an exception or return some default value\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Got unexpected status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Add a delay between 1 and 3 seconds before next request\n",
    "    # time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def find_all(string, substring):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = string.find(substring, start)\n",
    "        if start == -1: return\n",
    "        end = start + 100\n",
    "        yield string[start:end]\n",
    "        start += len(substring) # use start += 1 to find overlapping matches\n",
    "\n",
    "\n",
    "def get_cat_overview(url):\n",
    "\n",
    "\n",
    "    page = get_html_from_url(url)\n",
    "\n",
    "    substring_damen, substring_herren = \"/damen\", \"/herren\"\n",
    "\n",
    "\n",
    "    cat_urls_uncut_damen = set(find_all(page, substring_damen))\n",
    "    cat_urls_uncut_herren = set(find_all(page, substring_herren))\n",
    "\n",
    "\n",
    "\n",
    "    cat_urls_cut_damen, cat_urls_cut_herren, cat_names_damen, cat_names_herren = [],[],[],[]\n",
    "\n",
    "\n",
    "    for i in cat_urls_uncut_damen:\n",
    "        i = i.split(sep='\\\"')\n",
    "        cat_urls_cut_damen.append(\"https://www.vinted.de{}\".format(i[0]))\n",
    "        cat_names_damen.append(i[0])\n",
    "        # print(i)\n",
    "\n",
    "    for i in cat_urls_uncut_herren:\n",
    "        i = i.split(sep='\\\"')\n",
    "        cat_urls_cut_herren.append(\"https://www.vinted.de{}\".format(i[0]))\n",
    "        cat_names_herren.append(i[0])\n",
    "\n",
    "    print(\"We found {} categories for women on vinted that we can scrape\".format(len(cat_urls_uncut_damen)))\n",
    "    print(\"We found {} categories for men vinted that we can scrape\".format(len(cat_urls_uncut_herren)))\n",
    "    # for name in cat_names_damen:\n",
    "    #     print(name)\n",
    "    return cat_urls_cut_damen, cat_urls_cut_herren, cat_names_damen, cat_names_herren\n",
    "    \n",
    "\n",
    "\n",
    "def filter_doubles(titles_cut):\n",
    "    doubles = []\n",
    "    for i in titles_cut:\n",
    "        c = titles_cut.count(i)\n",
    "\n",
    "            # print(\"Title: {} occured {} times.\".format(i,c))\n",
    "        doubles.append((i,c))\n",
    "\n",
    "    set_d = set(doubles)\n",
    "    # for i in set_d:\n",
    "        # print(i)\n",
    "    names = list(set_d)\n",
    "    return names\n",
    "\n",
    "def get_display_titles(cat_urls_cut,cat_names):\n",
    "\n",
    "    c = 0\n",
    "    display_titles = []\n",
    "    pbar = tqdm(total=len(cat_urls_cut))\n",
    "    for url, name in zip(cat_urls_cut,cat_names):\n",
    "        # Send HTTP request to site and save the response from server in a response object called r\n",
    "        r = requests.get(url)\n",
    "        c += 1\n",
    "        # print(c)\n",
    "        \n",
    "        # Get the index of display title \n",
    "        index_title = r.text.find(\"<title>\")\n",
    "        title_uncut = r.text[index_title:index_title+100]\n",
    "        splt = title_uncut.split(sep=\" |\")\n",
    "        display_titles.append(splt[0])\n",
    "\n",
    "        # Create a BeautifulSoup object and specify the parser      \n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        filename = \"%s.txt\" % name[1:]\n",
    "        filename = filename.replace(\"/\",\"_\")\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "    titles_cut = []\n",
    "    for title in display_titles:\n",
    "        title = title[7:]\n",
    "        title = title.replace(\"&amp;\",\"\\\\u0026\")\n",
    "        titles_cut.append(title)\n",
    "    return titles_cut\n",
    "\n",
    "def get_display_titles_wrapper(cat_names_damen,cat_names_herren, cat_urls_cut_damen, cat_urls_cut_herren):\n",
    "    sub_path = path + '/categories'\n",
    "    if not os.path.exists(sub_path):\n",
    "        os.makedirs(sub_path)\n",
    "    # print(sub_path)\n",
    "\n",
    "    display_titles_damen = get_display_titles(cat_urls_cut_damen,cat_names_damen)\n",
    "    display_titles_herren = get_display_titles(cat_urls_cut_herren,cat_names_herren)\n",
    "\n",
    "    \n",
    "    titles_cut_with_count_damen = filter_doubles(display_titles_damen)\n",
    "    titles_cut_with_count_herren = filter_doubles(display_titles_herren)\n",
    "\n",
    "    return titles_cut_with_count_damen, titles_cut_with_count_herren\n",
    "\n",
    "\n",
    "\n",
    "def get_single_property(str:str,p:str):\n",
    "    i = str.find(p)\n",
    "    sub = str[i:]\n",
    "    sub = sub.split(\",\")\n",
    "    sub = sub[0]\n",
    "    prop_len = len(p)\n",
    "    name = sub[:prop_len]\n",
    "    sub = sub[prop_len+1:]\n",
    "    return name, sub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataframe(url, names, properties):\n",
    "\n",
    "    index_page = get_html_from_url(url)\n",
    "\n",
    "    for i in names:\n",
    "        start = 0\n",
    "        for j in range(i[1]):\n",
    "            \n",
    "            list_name = []\n",
    "            dict_props = {}\n",
    "            ind = index_page.find(i[0], start)\n",
    "            \n",
    "            # Get rough length to be cut \n",
    "            sub = index_page[ind-20:ind+1000]\n",
    "            \n",
    "            # Assign the new start for str.find() as to not retrieve the same index 2x\n",
    "            start = ind + len(sub)\n",
    "\n",
    "\n",
    "            sub = sub.replace(\"{\",\"\")\n",
    "            sub = sub.replace(\"\\\"\",\"\")\n",
    "\n",
    "            # Obtain all single desired properties of substring\n",
    "            for p in properties:\n",
    "                name, value = get_single_property(sub, p)\n",
    "                dict_props[p] = value\n",
    "\n",
    "\n",
    "            # convert the dictionary to a pandas DataFrame\n",
    "            df = pd.DataFrame(dict_props, index=[0])\n",
    "            yield df\n",
    "\n",
    "\n",
    "def get_dataframe_category(html,subs, props):\n",
    "\n",
    "    for i in subs:\n",
    "        dict_props = {}\n",
    "        ind = html.find(i)\n",
    "        \n",
    "        # Get rough length to be cut \n",
    "        sub = html[ind:ind+5000]\n",
    "        splt = sub.split(\"\\\",\\\"content_source\\\"\")\n",
    "        sub = splt[0]    \n",
    "\n",
    "\n",
    "        sub = sub.replace(\"{\",\"\")\n",
    "        sub = sub.replace(\"\\\"\",\"\")\n",
    "\n",
    "        # Obtain all single desired properties of substring\n",
    "        for p in props:\n",
    "            name, value = get_single_property(sub, p)\n",
    "            dict_props[p] = value\n",
    "\n",
    "\n",
    "        # convert the dictionary to a pandas DataFrame\n",
    "        df = pd.DataFrame(dict_props, index=[0])\n",
    "        # print(df.head())\n",
    "\n",
    "        yield df\n",
    "\n",
    "\n",
    "def get_announces_by_category(category_id, nr_pages, props):\n",
    "\n",
    "    properties_announce = ['id','title','price','brand_title','size_title','user:id','login','profile_url'] \n",
    "\n",
    "    for page in tqdm(range(nr_pages), leave=False):\n",
    "        try:\n",
    "                \n",
    "            url = \"https://www.vinted.de/catalog?catalog[]={}&page{}\".format(category_id,page+1)\n",
    "            # print(url)\n",
    "            html_string = get_html_from_url(url)\n",
    "            # print(html_string)\n",
    "\n",
    "            l = list(get_items_ids(html_string))\n",
    "            unique_id_references = [\"\\\"id\\\":\"+i for i in l]\n",
    "            # print(unique_id_references)\n",
    "\n",
    "            announces = list(get_dataframe_category(html=html_string, subs=unique_id_references, props= props))\n",
    "\n",
    "            announces_df = pd.concat(announces)\n",
    "            # print(announces_df.head())\n",
    "            # time.sleep(2)\n",
    "            yield announces_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            # logger.exception(e)\n",
    "            logger.error(\"Error getting Category Information\".format(e))\n",
    "\n",
    "def get_items_ids(page):\n",
    "    length = 1500\n",
    "    s = \"{\\\"catalogItems\\\":{\\\"ids\\\":\"\n",
    "    index = page.find(s)\n",
    "    sub = page[index:index+length]\n",
    "\n",
    "    # Remove everything around the ids\n",
    "    splts = sub.split(\"[\")\n",
    "    sub = splts[1]\n",
    "    splts = sub.split(\"]\")\n",
    "    sub = splts[0]\n",
    "    \n",
    "    splt = sub.split(\",\")\n",
    "    for i in splt:\n",
    "        yield i\n",
    "\n",
    "\n",
    "def save_to_Database(db,df):    \n",
    "    print(\"Function called\", flush=True)\n",
    "    today = date.today()\n",
    "    docs = None\n",
    "    docs = db.retrieve_data(today)\n",
    "    if docs != None:\n",
    "        print(docs,flush=True)\n",
    "    else:\n",
    "        print(\"Returned nothing form db\", flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFramePlotter:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        print('Launched Dataframe-Plotter')\n",
    "        self.folder_name = \"images/\" + date.today().strftime(\"%Y/%m/%d\") + '/'\n",
    "        if not os.path.exists(self.folder_name):\n",
    "            os.makedirs(self.folder_name)\n",
    "        # os.mkdir('images')\n",
    "        \n",
    "\n",
    "    # def plot_and_save(self, x, y, filename):\n",
    "    #     sns_plot = sns.scatterplot(data=self.df, x=x, y=y)\n",
    "    #     fig = sns_plot.get_figure()\n",
    "    #     fig.savefig(filename)\n",
    "    #     plt.clf()  # clear the figure\n",
    "\n",
    "\n",
    "    def plot_amount_categories_MW(self):\n",
    "        image_name = self.folder_name + 'amounts_category_MW.jpg'\n",
    "        x = ['women', 'men']\n",
    "        df = self.df[self.df['overview'] == 1]\n",
    "        print(len(df))\n",
    "\n",
    "        count_m = df['gender'].value_counts().get('m')\n",
    "        count_w = df['gender'].value_counts().get('w')\n",
    "        y = [count_w, count_m]\n",
    "        ax = sns.barplot(x=x, y=y, linewidth=0.5)\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(image_name)\n",
    "        # plt.clf()\n",
    "\n",
    "    def plot_amount_announces_per_category(self):\n",
    "        image_name = self.folder_name + 'amounts_per_category.jpg'\n",
    "\n",
    "        df = self.df[self.df['overview'] == 1]\n",
    "        df = df[df['title'] != '']\n",
    "        df = df[df['item_count'] != '']\n",
    "        df['item_count'] = df['item_count'].astype(int)\n",
    "        df_sorted = df.sort_values('item_count', ascending=False)\n",
    "        fig, ax = plt.subplots(figsize=(40, 20))\n",
    "        sns.barplot(data=df_sorted, x='title',y='item_count', ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), size=8)\n",
    "        ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "        for item in ax.get_xticklabels():\n",
    "            item.set_rotation(90)\n",
    "        plt.subplots_adjust(bottom=0.3)\n",
    "        fig = ax.get_figure()\n",
    "        \n",
    "        fig.savefig(image_name)\n",
    "\n",
    "\n",
    "    def plot_average_price_per_category(self):\n",
    "\n",
    "        image_name = self.folder_name + 'average_price_per_category.jpg'\n",
    "\n",
    "        df = self.df[self.df['overview'] == 0].copy()\n",
    "\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "        df = df.dropna(subset=['price'])\n",
    "        df['price'] = df['price'].astype(np.float32)\n",
    "\n",
    "\n",
    "        df['price'] = df['price'].astype(str)\n",
    "        df['price'] = df['price'].str.replace('[^0-9.]', '', regex=True)\n",
    "        df['price'] = df['price'].astype(float)\n",
    "        df = df.groupby('cat_title')['price'].mean().reset_index()\n",
    "\n",
    "        df['price'] = df['price'].astype(int)\n",
    "        df_sorted = df.sort_values('price', ascending=False)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(40, 20))\n",
    "        sns.barplot(data=df_sorted, x='cat_title',y='price', ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), size=8)\n",
    "        ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "        for item in ax.get_xticklabels():\n",
    "            item.set_rotation(90)\n",
    "        plt.subplots_adjust(bottom=0.3)\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(image_name)\n",
    "\n",
    "\n",
    "    def plot_announces_per_user(self):\n",
    "\n",
    "        image_name = self.folder_name + 'announces_per_user_top200.jpg'\n",
    "\n",
    "        df = self.df[self.df['overview'] == 0].copy()\n",
    "        df = df['login'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "        logger.debug(df.shape[0])\n",
    "        # Split data into three groups\n",
    "        first_200 = df[:200].reset_index()\n",
    "        # next_200 = df[200:400].reset_index()\n",
    "        # rest = df[400:].reset_index()\n",
    "        # print(first_200)\n",
    "\n",
    "        # Plot the first 200\n",
    "        fig, ax = plt.subplots(figsize=(40,20))\n",
    "        sns.barplot(data=first_200, x='index', y='login')\n",
    "        plt.title('Top 200 Users')\n",
    "        plt.xlabel('Users')\n",
    "        plt.ylabel('Counts')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "        plt.subplots_adjust(bottom=0.3)\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(image_name)\n",
    "\n",
    "        # # Plot the next 200\n",
    "        # plt.figure(figsize=(40,20))\n",
    "        # sns.barplot(data=next_200, x='index', y='login')\n",
    "        # plt.title('Next 200 Users')\n",
    "        # plt.xlabel('Users')\n",
    "        # plt.ylabel('Counts')\n",
    "        # plt.xticks(rotation=90)\n",
    "        # plt.show()\n",
    "\n",
    "        # # Plot the rest\n",
    "        # plt.figure(figsize=(40,20))\n",
    "        # sns.barplot(data=rest, x='index', y='login')\n",
    "        # plt.title('Remaining Users')\n",
    "        # plt.xlabel('Users')\n",
    "        # plt.ylabel('Counts')\n",
    "        # plt.xticks(rotation=90)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 283 categories for women on vinted that we can scrape\n",
      "We found 190 categories for men vinted that we can scrape\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd3e0bb010c48878cdf757d1d4c0ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad125dc0a144b4fa20658d518fd85c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                 title                     code item_count  \\\n",
      "0  1183  Mäntel \\u0026 Jacken  MATERNITY_COATS_JACKETS      19984   \n",
      "0  2630           Sportschuhe        WOMEN_SPORT_SHOES     706431   \n",
      "0    26         Sonnenbrillen               SUNGLASSES     629616   \n",
      "0   166           Schmucksets         WOM_ACC_JEW_SETS     405635   \n",
      "0  2632               Sneaker           WOMEN_TRAINERS    2978596   \n",
      "\n",
      "                                                 url gender  overview  \n",
      "0  /damen/kleidung/umstandskleidung/mantel-and-ja...      w         1  \n",
      "0                                                         w         1  \n",
      "0                   /damen/accessoires/sonnenbrillen      w         1  \n",
      "0             /damen/accessoires/schmuck/schmucksets      w         1  \n",
      "0                              /damen/schuhe/sneaker      w         1  \n",
      "['1183', '2630', '26', '166', '2632', '967', '229', '1125', '1846', '13', '962', '573', '2648', '1030', '1446', '120', '541', '213', '1442', '2645', '146', '534', '11', '1061', '152', '2528', '1093', '1843', '958', '1181', '192', '1097', '123', 'ng', '163', '227', '1078', '237', '158', '191', '958', '29', '197', '176', '201', '228', '1864', '189', '205', '220', '124', '580', '18', '155', '240', '235', '153', '1443', '88', '1087', '28', '2524', '1874', '14', '1041', '232', '1851', '1037', '538', '2527', '196', '577', '1184', '179', '1617', '548', '1834', '12', '2637', '2529', '1076', '1840', '2622', '88', '1090', '2655', '1126', '2688', '1263', '1781', '1442', '1842', '8', '89', '1841', '1778', '1070', '2651', '233', '1140', '1903', '2689', '223', '187', '543', '9', '218', '21', '539', '1066', '1058', '219', '', '1837', '2642', '1493', '1134', '964', '1850', '1264', '1185', '529', '542', '157', '1065', '1042', '1099', '1906', '2640', '215', '1849', '203', '1440', '2624', '1845', '540', '1616', '2650', '1037', '1441', '211', '1101', '156', '167', '', '', '1784', '160', '2530', '1086', '2618', '1773', '15', '1099', '1125', '572', '185', '8', '1129', '73', '204', '2636', '553', '2653', '1035', '2687', '1055', '2525', '1774', '2635', '2643', '194', '552', '1186', '1777', '1848', '1779', '236', '1103', '2639', '2644', '2641', '1615', '1100', '1221', '2532', '2531', '200', '1179', '2646', '191', '526', '195', '224', '164', '162', '1044', '178', '1094', '2614', '1123', '199', '2620', '29', '1092', '1079', '119', '950', '198', '1782', '1909', '1847', '2652', '2084', '225', '19', '962', '1785', '10', 'r', 'r', '1839', '2623', '1079', '1618', '1444', '90', '1071', '1067', '1844', '1902', '1445', '948', '1060', '2647', '193', '238', '1131', '1262', 'ng', '1847', '190', '234', '1043', '1128', '576', '1780', '2621', '2596', '2654', '2526', '1835', '1775', '159', '2649', '2619', '1049', '1057', '1852', '2633', '1080', '1838', '571', '1132', '184', '161', '1059', '2634', '1176', '1776', '2630', '26', '1823', '2632', '1789', '229', '1805', '1808', '2648', '1030', '1446', '1803', '213', '2645', '267', '152', '2528', '1843', '192', '958', 'ng', '1801', '1125', '9', '1078', '272', '158', '191', '1087', '2671', '1037', '538', '2527', '94', '1834', '12', '2529', '2622', '1076', '88', '2655', '1226', '1862', '1442', '8', '89', '1804', '92', '2651', '233', '97', '1821', '1802', '287', '21', '2661', '2642', '964', '1850', '157', '2640', '215', '1826', '2624', '1845', '2650', '1037', '1787', '1441', '1784', '156', '', '', '2530', '1086', '1807', '15', '1099', '572', '2636', '204', '553', '2653', '241', '93', '260', '142', '2525', '', '2635', '1815', '2643', '194', '85', '1848', '139', 'ng', '236', '2639', '1810', '1103', '2641', '2644', '2646', '2532', '1812', '259', '2531', '84', '536', '285', '2614', '1827', '29', '1079', '950', '1440', '1818', '2652', '197', '176', '201', '228', '1864', '189', '205', '220', '124', '580', '18', '155', '240', '235', '30', '289', '1443', '2662', '79', '585', '2623', '1079', '1444', '90', '261', '', '', '', '1844', '1445', '1902', '948', '2647', 'ng', '1847', '1800', '1262', '2524', '1874', '14', '2553', '190', '234', '576', '248', '1809', '2621', '1238', '2596', '2654', '2526', '2649', '1049', '2633', '1080', '571', '1806', '1813', '2634', '1790']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/bd_b6ytj5l916s0yf_qyvlp80000gq/T/ipykernel_97208/2315804948.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('\\\\u0026', '&')\n"
     ]
    }
   ],
   "source": [
    "# # Get MongoDB username, password, and hostname from environment variables\n",
    "# # username = os.environ['MONGO_USERNAME']\n",
    "# # password = os.environ['MONGO_PASSWORD']\n",
    "# # hostname = os.environ['MONGO_HOSTNAME']\n",
    "\n",
    "# # db = DB_Connector(username=username,password=password,hostname=hostname)\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "\n",
    "# Define the URL of the site\n",
    "url = f\"https://www.vinted.de/\"\n",
    "properties = ['id','title','code','item_count','url']\n",
    "properties_announce = ['id','title','price','brand_title','size_title','user:id','login','profile_url'] \n",
    "\n",
    "# Get CatNames\n",
    "cat_urls_cut_damen, cat_urls_cut_herren, cat_names_damen, cat_names_herren = get_cat_overview(url)\n",
    "\n",
    "display_titles_women, display_titles_men = get_display_titles_wrapper(cat_names_damen,cat_names_herren,cat_urls_cut_damen, cat_urls_cut_herren)\n",
    "\n",
    "\n",
    "dfs_women = list(get_dataframe(url, display_titles_women,properties))\n",
    "dfs_men = list(get_dataframe(url, display_titles_men,properties))\n",
    "combined_women = pd.concat(dfs_women)\n",
    "combined_men = pd.concat(dfs_men)\n",
    "\n",
    "combined_women['gender'] = 'w'\n",
    "combined_men['gender'] = 'm'\n",
    "\n",
    "df = pd.concat([combined_women, combined_men])\n",
    "\n",
    "df = df[df['id'] != 'null']\n",
    "df['overview'] = 1\n",
    "df['title'] = df['title'].str.replace('\\\\u0026', '&')\n",
    "print(df.head())\n",
    "# Check that there is no duplicates in list and have a look into the df\n",
    "\n",
    "# db.save_data(df)\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ========= Get announces by category ==============\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1183, 2630, 26, 166, 2632, 967, 229, 1125, 1846, 13, 962, 573, 2648, 1030, 1446, 120, 541, 213, 1442, 2645, 146, 534, 11, 1061, 152, 2528, 1093, 1843, 958, 1181, 192, 1097, 123, 163, 227, 1078, 237, 158, 191, 958, 29, 197, 176, 201, 228, 1864, 189, 205, 220, 124, 580, 18, 155, 240, 235, 153, 1443, 88, 1087, 28, 2524, 1874, 14, 1041, 232, 1851, 1037, 538, 2527, 196, 577, 1184, 179, 1617, 548, 1834, 12, 2637, 2529, 1076, 1840, 2622, 88, 1090, 2655, 1126, 2688, 1263, 1781, 1442, 1842, 8, 89, 1841, 1778, 1070, 2651, 233, 1140, 1903, 2689, 223, 187, 543, 9, 218, 21, 539, 1066, 1058, 219, 1837, 2642, 1493, 1134, 964, 1850, 1264, 1185, 529, 542, 157, 1065, 1042, 1099, 1906, 2640, 215, 1849, 203, 1440, 2624, 1845, 540, 1616, 2650, 1037, 1441, 211, 1101, 156, 167, 1784, 160, 2530, 1086, 2618, 1773, 15, 1099, 1125, 572, 185, 8, 1129, 73, 204, 2636, 553, 2653, 1035, 2687, 1055, 2525, 1774, 2635, 2643, 194, 552, 1186, 1777, 1848, 1779, 236, 1103, 2639, 2644, 2641, 1615, 1100, 1221, 2532, 2531, 200, 1179, 2646, 191, 526, 195, 224, 164, 162, 1044, 178, 1094, 2614, 1123, 199, 2620, 29, 1092, 1079, 119, 950, 198, 1782, 1909, 1847, 2652, 2084, 225, 19, 962, 1785, 10, 1839, 2623, 1079, 1618, 1444, 90, 1071, 1067, 1844, 1902, 1445, 948, 1060, 2647, 193, 238, 1131, 1262, 1847, 190, 234, 1043, 1128, 576, 1780, 2621, 2596, 2654, 2526, 1835, 1775, 159, 2649, 2619, 1049, 1057, 1852, 2633, 1080, 1838, 571, 1132, 184, 161, 1059, 2634, 1176, 1776, 2630, 26, 1823, 2632, 1789, 229, 1805, 1808, 2648, 1030, 1446, 1803, 213, 2645, 267, 152, 2528, 1843, 192, 958, 1801, 1125, 9, 1078, 272, 158, 191, 1087, 2671, 1037, 538, 2527, 94, 1834, 12, 2529, 2622, 1076, 88, 2655, 1226, 1862, 1442, 8, 89, 1804, 92, 2651, 233, 97, 1821, 1802, 287, 21, 2661, 2642, 964, 1850, 157, 2640, 215, 1826, 2624, 1845, 2650, 1037, 1787, 1441, 1784, 156, 2530, 1086, 1807, 15, 1099, 572, 2636, 204, 553, 2653, 241, 93, 260, 142, 2525, 2635, 1815, 2643, 194, 85, 1848, 139, 236, 2639, 1810, 1103, 2641, 2644, 2646, 2532, 1812, 259, 2531, 84, 536, 285, 2614, 1827, 29, 1079, 950, 1440, 1818, 2652, 197, 176, 201, 228, 1864, 189, 205, 220, 124, 580, 18, 155, 240, 235, 30, 289, 1443, 2662, 79, 585, 2623, 1079, 1444, 90, 261, 1844, 1445, 1902, 948, 2647, 1847, 1800, 1262, 2524, 1874, 14, 2553, 190, 234, 576, 248, 1809, 2621, 1238, 2596, 2654, 2526, 2649, 1049, 2633, 1080, 571, 1806, 1813, 2634, 1790]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Assuming df is your DataFrame and 'col_name' is your column\n",
    "df['id'] = pd.to_numeric(df['id'], errors='coerce')\n",
    "df = df.dropna(subset=['id'])\n",
    "df['id'] = df['id'].astype(np.int64)\n",
    "\n",
    "\n",
    "cat_ids = df['id'].values.tolist()\n",
    "cat_titles = df['title'].values.tolist()\n",
    "\n",
    "# cat_ids = cat_ids[cat_idss['id'].notna()]\n",
    "# cat_ids = cat_ids[:10]\n",
    "print(cat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(cat_ids))\n",
    "for i, j in zip(cat_ids, cat_titles):\n",
    "    try:\n",
    "        announces = list(get_announces_by_category(i, 5, properties_announce))\n",
    "        df_cat = pd.concat(announces)\n",
    "        df_cat['cat_id'] = i\n",
    "        df_cat['cat_title'] = j\n",
    "        df_cat['overview'] = 0\n",
    "        # db.save_data(df_cat)\n",
    "        df =  pd.concat([df, df_cat])\n",
    "        pbar.update()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "pbar.close()\n",
    "# test_df = db.retrieve_data(date=date.today())\n",
    "# df = pd.DataFrame(test_df)\n",
    "# df.to_csv('mydf.csv',index=False)\n",
    "print(df)\n",
    "print(type(df))\n",
    "print(df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/bd_b6ytj5l916s0yf_qyvlp80000gq/T/ipykernel_97208/403444456.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('\\\\u0026', '&')\n"
     ]
    }
   ],
   "source": [
    "df['title'] = df['title'].str.replace('\\\\u0026', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFramePlotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zs/bd_b6ytj5l916s0yf_qyvlp80000gq/T/ipykernel_25403/1903131365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFramePlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_amount_categories_MW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_amount_announces_per_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_average_price_per_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataFramePlotter' is not defined"
     ]
    }
   ],
   "source": [
    "plotter = DataFramePlotter(df)\n",
    "plotter.plot_amount_categories_MW()\n",
    "plotter.plot_amount_announces_per_category()\n",
    "plotter.plot_average_price_per_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zs/bd_b6ytj5l916s0yf_qyvlp80000gq/T/ipykernel_25403/2921148620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_announces_per_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plotter' is not defined"
     ]
    }
   ],
   "source": [
    "plotter.plot_announces_per_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
